# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
from google.colab import files
uploaded = files.upload()  # Upload your 'car data.csv' file here

# Load the dataset into a DataFrame
car_data = pd.read_csv('car data.csv')  # The dataset will appear here after upload
car_data.head()  # Display the first few rows of the dataset
# Step 1: Data Preprocessing

# Create a new column 'Age' by subtracting the 'Year' from the current year
car_data['Age'] = 2024 - car_data['Year']

# Drop 'Year' and 'Car_Name' as they are not necessary for the model
car_data = car_data.drop(columns=['Year', 'Car_Name'])

# Encode categorical variables using LabelEncoder
labelencoder = LabelEncoder()
car_data['Fuel_Type'] = labelencoder.fit_transform(car_data['Fuel_Type'])
car_data['Selling_type'] = labelencoder.fit_transform(car_data['Selling_type'])
car_data['Transmission'] = labelencoder.fit_transform(car_data['Transmission'])

# Display the preprocessed data
car_data.head()  # Check the processed data
# Step 2: Define Features and Target
X = car_data.drop(columns=['Selling_Price'])  # Features
y = car_data['Selling_Price']  # Target

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the training and testing data shapes
print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)
# Step 3: Model Training

# Using RandomForestRegressor for this task
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Display a message that the model has been trained
print("Random Forest model has been trained.")
plt.figure(figsize=(8, 5))
sns.histplot(car_data['Selling_Price'], kde=True, color='blue')
plt.title('Distribution of Selling Price')
plt.xlabel('Selling Price')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(8, 5))
sns.scatterplot(x=car_data['Age'], y=car_data['Selling_Price'], hue=car_data['Fuel_Type'], palette='Set1')
plt.title('Car Age vs. Selling Price')
plt.xlabel('Age of Car (in years)')
plt.ylabel('Selling Price')
plt.show()

plt.figure(figsize=(8, 5))
sns.scatterplot(x=car_data['Present_Price'], y=car_data['Selling_Price'], hue=car_data['Transmission'], palette='Set2')
plt.title('Present Price vs. Selling Price')
plt.xlabel('Present Price (Ex-showroom price)')
plt.ylabel('Selling Price')
plt.show()

plt.figure(figsize=(10, 6))
correlation_matrix = car_data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

y_pred = rf_model.predict(X_test)

# Step 5: Model Evaluation

# Mean Squared Error (MSE) and R-Squared
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Printing Results
print(f"Mean Squared Error: {mse}")
print(f"R-Squared: {r2}")
